{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = { re.search('/([^/\\.]*)\\.csv', fn).group(0):\n",
    "dfs = { re.search('(\\w+)\\.csv', fn).group(1): pd.read_csv(fn) for fn in glob.glob('../rawdata/*.csv')}\n",
    "for k, v in dfs.items(): locals()[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找到既属于周末，又是节假日的日期\n",
    "wkend_holidays = date_info.apply(lambda x: (x.day_of_week=='Sunday' or x.day_of_week=='Saturday') and x.holiday_flg==1, axis=1)\n",
    "#将这些日期视为周末\n",
    "date_info.loc[wkend_holidays, 'holiday_flg'] = 0\n",
    "\n",
    "date_info['weight'] = ((date_info.index + 1) / len(date_info)) ** 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_data = air_visit_data.merge(date_info, left_on='visit_date', right_on='calendar_date', how='left')\n",
    "\n",
    "visit_data.drop('calendar_date', axis=1, inplace=True)\n",
    "\n",
    "visit_data['visitors'] = visit_data.visitors.map(pd.np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>1.005227e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>1.456087e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>2.055908e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>2.838881e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>5.115756e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors day_of_week  holiday_flg  \\\n",
       "0  air_ba937bf13d40fb24  2016-01-13  3.258097   Wednesday            0   \n",
       "1  air_ba937bf13d40fb24  2016-01-14  3.496508    Thursday            0   \n",
       "2  air_ba937bf13d40fb24  2016-01-15  3.401197      Friday            0   \n",
       "3  air_ba937bf13d40fb24  2016-01-16  3.135494    Saturday            0   \n",
       "4  air_ba937bf13d40fb24  2016-01-18  1.945910      Monday            0   \n",
       "\n",
       "         weight  \n",
       "0  1.005227e-08  \n",
       "1  1.456087e-08  \n",
       "2  2.055908e-08  \n",
       "3  2.838881e-08  \n",
       "4  5.115756e-08  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按照id、周几、是否为节假日分组，在每组内进行顾客数的归一化计算\n",
    "visitors = visit_data.groupby(['air_store_id', 'day_of_week', 'holiday_flg']).apply(lambda x:( (x.weight * x.visitors).sum() / x.weight.sum() )).reset_index()\n",
    "visitors.rename(columns={0:'visitors'}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>3.583535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>3.203625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>3.091042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>2.524065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id day_of_week  holiday_flg  visitors\n",
       "0  air_00a91d42b08b08d9      Friday            0  3.583535\n",
       "1  air_00a91d42b08b08d9      Monday            0  3.203625\n",
       "2  air_00a91d42b08b08d9      Monday            1  3.091042\n",
       "3  air_00a91d42b08b08d9    Saturday            0  2.524065\n",
       "4  air_00a91d42b08b08d9      Sunday            0  1.098612"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visitors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用 split根据‘_' 切割air_00a91d42b08b08d9_2017-04-23这样的合成ID\n",
    "#使用‘_' join 不包括最后一个元素的其他元素（即不包括日期）\n",
    "sample_submission['air_store_id'] = sample_submission.id.map(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "\n",
    "sample_submission['calendar_date'] = sample_submission.id.map(lambda x: x.split('_')[2])\n",
    "\n",
    "sample_submission.drop('visitors', axis=1, inplace=True)\n",
    "\n",
    "#统计每个店，周几以及是否为节假日的人数情况，作为预测时间段内相应条目的结果\n",
    "sample_submission = sample_submission.merge(date_info, on='calendar_date', how='left')\n",
    "sample_submission = sample_submission.merge(visitors, on=['air_store_id', 'day_of_week', 'holiday_flg'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "missings = sample_submission.visitors.isnull()\n",
    "#如果没有店ID、周几、是否为节假日三个条件完全一致的历史数据，则以店ID、周几两个条件一致，取非节假日的数据填充\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(visitors[visitors.holiday_flg==0], on=('air_store_id', 'day_of_week'), how='left')['visitors_y'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果店ID、周几两个条件都不能同时满足，则取各个店的数据取均值\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(visitors[['air_store_id', 'visitors']].groupby('air_store_id').mean().reset_index(), on='air_store_id', how='left')['visitors_y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_visit_var = sample_submission.visitors.map(pd.np.expm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 纯粹的历史数据统计，结果为0.497 public LB\n",
    "# ans=sample_submission.copy()\n",
    "# ans['visitors']=test_visit_var\n",
    "# ans[['id','visitors']].to_csv('../result/090501_pure_stats.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'tra': pd.read_csv('../rawdata/air_visit_data.csv')\n",
    "    }\n",
    "\n",
    "data['tra'] = data['tra'].merge(date_info, left_on='visit_date', right_on='calendar_date', how='left')\n",
    "data['tra'] = data['tra'].merge(visitors, on=['air_store_id', 'day_of_week', 'holiday_flg'], how='left')\n",
    "\n",
    "missings = data['tra'].visitors_y.isnull()\n",
    "data['tra'].loc[missings, 'visitors_y'] = data['tra'][missings].merge(visitors[visitors.holiday_flg==0], on=('air_store_id', 'day_of_week'), how='left')['visitors_y'].values\n",
    "\n",
    "missings = data['tra'].visitors_y.isnull()\n",
    "data['tra'].loc[missings, 'visitors_y'] = data['tra'][missings].merge(visitors[['air_store_id', 'visitors']].groupby('air_store_id').mean().reset_index(), on='air_store_id', how='left')['visitors_y'].values\n",
    "\n",
    "train_visit_var = data['tra'].visitors_y.map(pd.np.expm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'tra': pd.read_csv('../rawdata/air_visit_data.csv'),\n",
    "    'as': pd.read_csv('../rawdata/air_store_info.csv'),\n",
    "    'hs': pd.read_csv('../rawdata/hpg_store_info.csv'),\n",
    "    'ar': pd.read_csv('../rawdata/air_reserve.csv'),\n",
    "    'hr': pd.read_csv('../rawdata/hpg_reserve.csv'),\n",
    "    'id': pd.read_csv('../rawdata/store_id_relation.csv'),\n",
    "    'tes': pd.read_csv('../rawdata/sample_submission.csv'),\n",
    "    'hol': pd.read_csv('../rawdata/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in ['ar','hr']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime']).dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime']).dt.date\n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n",
    "    tmp1 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs1', 'reserve_visitors':'rv1'})\n",
    "    tmp2 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].mean().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs2', 'reserve_visitors':'rv2'})\n",
    "    data[df] = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n",
    "\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test中所有餐厅，周一到周日的空表格，储存在stores中\n",
    "unique_stores = data['tes']['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp = data['tra'].groupby(['air_store_id','dow']).agg({'visitors' : [np.min,np.mean,np.median,np.max,np.size]}).reset_index()\n",
    "tmp.columns = ['air_store_id', 'dow', 'min_visitors', 'mean_visitors', 'median_visitors','max_visitors','count_observations']\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "\n",
    "stores = pd.merge(stores, data['as'], how='left', on=['air_store_id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.457143</td>\n",
       "      <td>19.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.920635</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Izakaya</td>\n",
       "      <td>Tōkyō-to Taitō-ku Higashiueno</td>\n",
       "      <td>35.712607</td>\n",
       "      <td>139.779996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_0328696196e46f18</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.416667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Ōsaka-fu Ōsaka-shi Nakanochō</td>\n",
       "      <td>34.701279</td>\n",
       "      <td>135.528090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_034a3d5b40d5b1b1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.864865</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Cafe/Sweets</td>\n",
       "      <td>Ōsaka-fu Ōsaka-shi Ōhiraki</td>\n",
       "      <td>34.692337</td>\n",
       "      <td>135.472229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  dow  min_visitors  mean_visitors  median_visitors  \\\n",
       "0  air_00a91d42b08b08d9    0           1.0      22.457143             19.0   \n",
       "1  air_0164b9927d20bcc3    0           2.0       7.500000              6.0   \n",
       "2  air_0241aa3964b7f861    0           2.0       8.920635              8.0   \n",
       "3  air_0328696196e46f18    0           2.0       6.416667              4.0   \n",
       "4  air_034a3d5b40d5b1b1    0           1.0      11.864865             10.0   \n",
       "\n",
       "   max_visitors  count_observations  air_genre_name  \\\n",
       "0          47.0                35.0  Italian/French   \n",
       "1          19.0                20.0  Italian/French   \n",
       "2          23.0                63.0         Izakaya   \n",
       "3          27.0                12.0      Dining bar   \n",
       "4          66.0                37.0     Cafe/Sweets   \n",
       "\n",
       "                     air_area_name   latitude   longitude  \n",
       "0  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595  \n",
       "1     Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599  \n",
       "2    Tōkyō-to Taitō-ku Higashiueno  35.712607  139.779996  \n",
       "3     Ōsaka-fu Ōsaka-shi Nakanochō  34.701279  135.528090  \n",
       "4       Ōsaka-fu Ōsaka-shi Ōhiraki  34.692337  135.472229  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "stores['air_genre_name'] = stores['air_genre_name'].map(lambda x: str(str(x).replace('/',' ')))\n",
    "stores['air_area_name'] = stores['air_area_name'].map(lambda x: str(str(x).replace('-',' ')))\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for i in range(10):\n",
    "    stores['air_genre_name'+str(i)] = lbl.fit_transform(stores['air_genre_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "    stores['air_area_name'+str(i)] = lbl.fit_transform(stores['air_area_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n",
    "\n",
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date']) \n",
    "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date']) \n",
    "\n",
    "train = pd.merge(train, stores, how='left', on=['air_store_id','dow']) \n",
    "test = pd.merge(test, stores, how='left', on=['air_store_id','dow'])\n",
    "\n",
    "for df in ['ar','hr']:\n",
    "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n",
    "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n",
    "\n",
    "train['id'] = train.apply(lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), axis=1)\n",
    "\n",
    "train['total_reserv_sum'] = train['rv1_x'] + train['rv1_y']\n",
    "train['total_reserv_mean'] = (train['rv2_x'] + train['rv2_y']) / 2\n",
    "train['total_reserv_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y']) / 2\n",
    "\n",
    "test['total_reserv_sum'] = test['rv1_x'] + test['rv1_y']\n",
    "test['total_reserv_mean'] = (test['rv2_x'] + test['rv2_y']) / 2\n",
    "test['total_reserv_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['air_store_id', 'visit_date', 'visitors', 'dow', 'year', 'month',\n",
       "       'day_of_week', 'holiday_flg', 'min_visitors', 'mean_visitors',\n",
       "       'median_visitors', 'max_visitors', 'count_observations',\n",
       "       'air_genre_name', 'air_area_name', 'latitude', 'longitude',\n",
       "       'air_genre_name0', 'air_area_name0', 'air_genre_name1',\n",
       "       'air_area_name1', 'air_genre_name2', 'air_area_name2',\n",
       "       'air_genre_name3', 'air_area_name3', 'air_genre_name4',\n",
       "       'air_area_name4', 'air_genre_name5', 'air_area_name5',\n",
       "       'air_genre_name6', 'air_area_name6', 'air_genre_name7',\n",
       "       'air_area_name7', 'air_genre_name8', 'air_area_name8',\n",
       "       'air_genre_name9', 'air_area_name9', 'rs1_x', 'rv1_x', 'rs2_x', 'rv2_x',\n",
       "       'rs1_y', 'rv1_y', 'rs2_y', 'rv2_y', 'id', 'total_reserv_sum',\n",
       "       'total_reserv_mean', 'total_reserv_dt_diff_mean', 'date_int',\n",
       "       'var_max_lat', 'var_max_long', 'lon_plus_lat', 'air_store_id2',\n",
       "       'hklee_feature'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW FEATURES FROM JMBULL\n",
    "train['date_int'] = train['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "test['date_int'] = test['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "train['var_max_lat'] = train['latitude'].max() - train['latitude']\n",
    "train['var_max_long'] = train['longitude'].max() - train['longitude']\n",
    "test['var_max_lat'] = test['latitude'].max() - test['latitude']\n",
    "test['var_max_long'] = test['longitude'].max() - test['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "train['lon_plus_lat'] = train['longitude'] + train['latitude'] \n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "train['air_store_id2'] = lbl.fit_transform(train['air_store_id'])\n",
    "test['air_store_id2'] = lbl.transform(test['air_store_id'])\n",
    "\n",
    "train['hklee_feature'] = train_visit_var \n",
    "test['hklee_feature'] = test_visit_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date','visitors']]\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
